DL Experiments (Deep Learning)

#эксперимент : название : дата
датасет;
описание;
    результаты;

#00 : SR_ResNet18_L1_x0.25 : 03.02.2021
DIV2K;
Самопальный ResNet, сделанный из torchvision.models.resnet18, обучение на локалке, скейлинг всех картинок (и training, и validation) x0.25 в целях экономии памяти на валидации, метрика PSNR, step decay;
    Успешное подтверждение компилируемости написанного кода;

#01 : RDN_L1_x0.5 : 03.02.2021
DIV2K;
Переход на модель RDN, переезд на colab, скейлинг всех картинок x0.5;
    При валидации на x1 картинках DIV2K достигнут почти результат paper-а (32.35db), лучших результатов для Supervised больше не было;

#02 : RDN_L1_x1 : 03.02.2021
DIV2K;
Избавились от скейлинга, заменив его кропом, дообучаем модель из RDN_L1_x0.5;
    PSNR хуже чем без дообучения на ~0.5db;

#03 : RDN_L1_VGG_x1 : 04.02.2021
DIV2K;
Применение VGG лосса, дообучаем модель из RDN_L1_x1;
    PSNR хуже еще на ~0.2db, но картинки стали заметно чётче;

#04 : RDN_PureVGG_x1 : 04.02.2021
DIV2K;
Обучение на чистом VGG без L1, с нуля (рандомная инициализация весов);
    PSNR значительно хуже на ~5db, картинки не лучше предыдущих;

#05 : SR_ResNet18_L1_VGG_x1_Warmup : 05.02.2021
DIV2K;
Возвращение к старой модели ResNet, но обучение с помощью текущих лучших лоссов, добавление warmup, дообучение SR_ResNet18_L1_x0.25, сохранение кропов;
    Ужасное качество изображения, артефакты локально "взрывающихся" градиентов;

#06 : RDN_L1_VGG_x1_Warmup : 05.02.2021
DIV2K;
Дообучение RDN_L1_x0.5 с warmup, блюрим LR-ы;
    Явная демонстрация работы сетки, но вне блюрного домена получается овершарп, модель бесполезна;

#07 : RDN_L1_VGG_x4_Warmup : 05.02.2021
DIV2K;
Попытка x4 SR;
    То ли мало эпох, то ли не попали в настройки, эксперимент неудачный, ужасное качество;

Где-то тут несколько экспериментов на умершей тачке, они безвозвратно утеряны, заполняю по памяти.

#07.5 : Test_GAN : 22.03.2021
DIV2K;
Тестовая попытка запуска Conditional LSGAN на джобе;
    Хорошие результаты, гораздо лучше Supervised;

#08 : Test_GAN_Warmup_Colab : 02.03.2021
Bakemonogatari_1000 (reference);
Тестовая попытка запуска Conditional LSGAN на colab, не помню что там было;
    Вполне нормальные результаты, надо было побольше пообучать;

#09 : GAN_L1_VGG_Plain_Bad : 02.03.2021
Bakemonogatari_1000;
L1 0.01, VGG 1.0, GAN 0.1, SimpleConvDiscr;
    Взрыв модели, генерируется неплохой acid trip;

#10 : GAN_L1_VGG_Aug_Bad : 03.03.2021
Bakemonogatari_1000;
Добавили аугментации, downscaling x0.5 + blur + sharp;
    Взрыв модели, генерируется качественный acid trip;

#11 : GAN_L1_VGG_Rev_Hard_Aug : 03.03.2021
Bakemonogatari_1000;
Сильнее аугментации, усиленный дискриминатор RevDiscr;
    Сетка научилась сильно блюрить картинку, зато шум убирается, хаха;

#12 : GAN_L1_VGG_Rev_Aug : 03.03.2021
Bakemonogatari_1000;
Аугментации как в GAN_L1_VGG_Aug_Bad;
    Сетка научилась блюрить картинку не так сильно;

#13 : GAN_L1_VGG_Rev_Hard_Aug_v2 : 04.03.2021
Bakemonogatari_1000;
Дообучение GAN_L1_VGG_Rev_Hard_Aug, но с меньшими аугментациями;
    Сетка научилась блюрить картинку не так сильно;

#14 : GAN_L1_VGG_RevNorm : 04.03.2021
Bakemonogatari_1000;
Аугментации из GAN_L1_VGG_Rev_Aug, добавили батчнорм в дискриминатор;
    Сетка научилась блюрить картинку не так сильно, как в GAN_L1_VGG_Rev_Hard_Aug_v2, но сильнее, чем в GAN_L1_VGG_Rev_Aug;

#15 : GAN_L1_VGG_RevNorm_x0.25_Pretrained_RevNorm : 08.03.2021
Bakemonogatari_1000;
Аугментация downscaling x0.25, загружаем претренированный хз что;
    Прикольно делает x4 SR, для другого не годится;

#16 : GAN_L1_VGG_RevNorm_RealSR : 09.03.2021
Bakemonogatari_1000;
26 кернелов, 100 патчей шума, первый пуск RealSR;
    Слишком сильный шум, содержащий контент, приводит к замазыванию линий;

#17 : GAN_L1_VGG_Norm_Real_HalfNoise : 11.03.2021
Bakemonogatari_1000;
Вполовину уменьшенная сила шума;
    Линии замазываются меньше, но все равно значительно;

#18 : GAN_L1_VGG_Norm_Noise1000 : 12.03.2021
Bakemonogatari_1000;
60 кернелов, 1000 патчей шума;
    Картинки стали сильно блюрнее;

#19 : GAN_L1_VGG_Norm_NoiseBlur1000 : 12.03.2021
Bakemonogatari_1000;
Фильтруем шум двухэтапной экстракцией, тем самым избавляемся от контента;
    Линии перестали замазываться совсем, сетка перестала быть робастной к сильному шуму;

#20 : GAN_L1_VGG_Norm_NoiseBlurScaleHR : 13.03.2021
Bakemonogatari_1000;
Скейлим HR-ы так, чтобы толщина линий референса совпала с толщиной линий в таргете;
    Очень четкие, резкие изображения, нет робастности к шуму;

#21 : GAN_L1_VGG_Norm_NoiseBlurS4K3ScaleHR : 14.03.2021
Bakemonogatari_1000;
Попытка немного усилить шум и дообучить модель из GAN_L1_VGG_Norm_NoiseBlurScaleHR, чтобы сделать ее менее воприимчивой к шуму;
    Неудача - вместе с лучшей обработкой шума стали замазываться линии;

#22 : GAN_L1_VGG_Norm_NoiseBlurS3K3ScaleHR : 15.03.2021
Bakemonogatari_1000;
Аналогично GAN_L1_VGG_Norm_NoiseBlurS4K3ScaleHR;
    Аналогично GAN_L1_VGG_Norm_NoiseBlurS4K3ScaleHR;

#23 : GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080 : 16.03.2021
Bakemonogatari_1000;
Пробуем менять Aspect Ratio и дополнительно скейлить LR-ы, чтобы сделать SR в 1920x1080, см. иллюстрацию;
    В принципе успех, но проблемы с шумом уже встали во весь рост;

#24 : GAN_L1_VGG_Norm_NoiseBlur_DIV2K : 17.03.2021
DIV2K;
Пробуем поменять reference на DIV2K;
    Ужасный шум, никакого шарпа, но эксперимент успешен - доказательство необходимости reference;

#25 : GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper : 18.03.2021
Bakemonogatari_4000;
Смена исходников target-а на менее шумные, хотя и немного менее резкие, 1000 кернелов, 4000 патчей шума, степпер для контроля обучения дискриминатора, очень слабый шум;
    Степпер огонь, линии стали четче, чем в GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080, но из-за слабости шума результаты, казалось бы, парадоксально стали более шумными;

#26 : GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_DownAug : 19.03.2021
Bakemonogatari_4000;
Все то же самое, что и в GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper, плюс аугментация downscaling x0.5;
    Немного лучшая обработка шума, но резкость ухудшилась, доказана бесполезность downscaling;

#27 : GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast : 19.03.2021
Bakemonogatari_4000;
Все то же самое, что и в GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper, плюс аугментация повышение контраста, мотивация - большая контрастность target, чем reference;
    Модель взорвалась, неудача;

#28 : GAN_L1_VGG_Norm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast : 20.03.2021
Bakemonogatari_4000;
Все то же самое, что и в GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast, но агментация контраста не такая сильная, плюс уменьшаем контраст тоже;
    Успех, отличные результаты по шуму и резкости;

#29 : GAN_L1_VGG_Norm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast_Edge : 22.03.2021
Bakemonogatari_4000;
Добавляем Edge Loss с коэффициентом 2 (абсолютное значение VGG / 10);
    Совершенно незначительно (едва заметно даже при увеличении) улучшилась резкость линий;

#30 : GAN_L1_VGG_Norm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast_Edge_Alias_Transpose : 01.04.2021
Bakemonogatari_4000;
Заменили PixelShuffle на BlurPool + ConvTranspose чтобы избавиться от чекерборд артефактов;
    Неправильная последовательность действий, плохие результаты, артефакты усилились;

#31 : GAN_L1_VGG_Norm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast_Edge_Alias : 01.04.2021
Bakemonogatari_4000;
Правильный порядок действий PixelShuffle + BlurPool;
    Шах и мат чекербордам, заодно все метрики скакнули, например, PSNR лучше на 4+db;

#32 : GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3W5K5_Stepper_Contrast_Edge_Alias : 03.04.2021
Bakemonogatari_1000;
Все то же самое, что и в GAN_L1_VGG_Norm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast_Edge_Alias, но посильнее шум и меньше reference датасет;
    Линии замазываются, неудача;

#33 : GAN_L1_VGG_RevNorm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast_Edge_Alias : 03.04.2021
Bakemonogatari_1000;
Все то же самое, что и в GAN_L1_VGG_Norm_NoiseBlur_AR_ES1080_AniBoters_S3K3_Stepper_Contrast_Edge_Alias, но меньше reference датасет;
    Идентичные результаты, чуть лучше обработка шума;

CM Experiments (Common)

Пост-процессинг: денойз, автоконтраст, дизеринг
1) Денойз. Обычный cv2 денойз замазывает линии покруче самой сетки, что неудивительно, ведь мы сетку как раз этим алгоритмом и обучали. Применение двойного экстракшена позволяет снизить заблюривание, но для получения приемлимого уровня денойза необходим баланс, так что картинка все равно немного смазывается. Но это необходимо, так как при обучении с маленьким шумом сетка выдает довольно шумные предикшены;
2) Автоконтраст. Растягиваем гистограмму, но не просто линейным преобразованием, а улучшенным алгоритмом. В алгоритме есть баг, который приводи к нестабильности (заметное уменьшение яркости, превращающееся в мигание на видео) на изображениях с низким динамическим диапазоном. Вывод - не используем.
3) Дизеринг. В текущем исполнении помогает для двухэтапного денойза, бесполезен для всего остального, так как алгоритм денойза 8-ми битный.
